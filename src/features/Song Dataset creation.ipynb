{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 08:46:11.749573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-24 08:46:11.749602: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"audioset_v1_embeddings/eval\"\n",
    "dataset = []\n",
    "for file_name in os.listdir(directory):\n",
    "     if file_name.endswith(\".tfrecord\"):\n",
    "            dataset.append(os.path.join(directory,file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 08:49:52.641696: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-24 08:49:52.641732: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-24 08:49:52.641759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (debian): /proc/driver/nvidia/version does not exist\n",
      "2022-06-24 08:49:52.644310: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = pd.read_csv('class_labels_indices.csv')\n",
    "labels = class_labels['display_name'].tolist()\n",
    "music_class = class_labels[class_labels['display_name'].str.contains('Music', case=False)]\n",
    "music_labels = music_class['index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = []\n",
    "NUM_SECONDS = 10\n",
    "for raw_record in raw_dataset: # Load 2,000 files\n",
    "    example = tf.train.SequenceExample()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    # Metadata of samples\n",
    "    audio_labels = example.context.feature['labels'].int64_list.value\n",
    "    start_time = example.context.feature['start_time_seconds'].float_list.value\n",
    "    end_time = example.context.feature['end_time_seconds'].float_list.value\n",
    "    video_id = example.context.feature['video_id'].bytes_list.value\n",
    "    if not (set(music_labels) & set(audio_labels)):\n",
    "        continue\n",
    "    # Feature\n",
    "    feature_list = example.feature_lists.feature_list['audio_embedding'].feature\n",
    "    final_features = [list(feature.bytes_list.value[0]) for feature in feature_list]\n",
    "    audio_embedding = [item for sublist in final_features[:NUM_SECONDS] for item in sublist]\n",
    "    if len(final_features) < NUM_SECONDS:\n",
    "        continue\n",
    "    audio = {\n",
    "        'label': audio_labels, \n",
    "        'video_id': video_id[0], \n",
    "        'start_time': start_time[0], \n",
    "        'end_time': end_time[0],\n",
    "        'data': audio_embedding\n",
    "    }\n",
    "    audios.append(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('music_set.json', 'w') as file:\n",
    "    str_audio = repr(audios)\n",
    "    json.dump(str_audio, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "db9e6ccaa75d75eacee9c365126bc391415ec486aa256e972df5001442128dbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
